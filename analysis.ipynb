{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8afa33",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c396603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running covariance computation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class OnlineCovariance:\n",
    "    \"\"\"\n",
    "    A class to calculate the mean and the covariance matrix\n",
    "    of the incrementally added, n-dimensional data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, order):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        order: int, The order (==\"number of features\") of the incrementally added\n",
    "        dataset and of the resulting covariance matrix.\n",
    "        \"\"\"\n",
    "        self._order = order\n",
    "        self._shape = (order, order)\n",
    "        self._identity = np.identity(order)\n",
    "        self._ones = np.ones(order)\n",
    "        self._count = 0\n",
    "        self._mean = np.zeros(order)\n",
    "        self._cov = np.zeros(self._shape)\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        \"\"\"\n",
    "        int, The number of observations that has been added\n",
    "        to this instance of OnlineCovariance.\n",
    "        \"\"\"\n",
    "        return self._count\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        \"\"\"\n",
    "        double, The mean of the added data.\n",
    "        \"\"\"\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def cov(self):\n",
    "        \"\"\"\n",
    "        array_like, The covariance matrix of the added data.\n",
    "        \"\"\"\n",
    "        return self._cov\n",
    "\n",
    "    @property\n",
    "    def corrcoef(self):\n",
    "        \"\"\"\n",
    "        array_like, The normalized covariance matrix of the added data.\n",
    "        Consists of the Pearson Correlation Coefficients of the data's features.\n",
    "        \"\"\"\n",
    "        if self._count < 1:\n",
    "            return None\n",
    "        variances = np.diagonal(self._cov)\n",
    "        denomiator = np.sqrt(variances[np.newaxis, :] * variances[:, np.newaxis])\n",
    "        return self._cov / denomiator\n",
    "\n",
    "    def add(self, observation):\n",
    "        \"\"\"\n",
    "        Add the given observation to this object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation: array_like, The observation to add.\n",
    "        \"\"\"\n",
    "        if self._order != len(observation):\n",
    "            raise ValueError(f\"Observation to add must be of size {self._order}\")\n",
    "\n",
    "        self._count += 1\n",
    "        delta_at_nMin1 = np.array(observation - self._mean)\n",
    "        self._mean += delta_at_nMin1 / self._count\n",
    "        weighted_delta_at_n = np.array(observation - self._mean) / self._count\n",
    "        shp = (self._order, self._order)\n",
    "        D_at_n = np.broadcast_to(weighted_delta_at_n, self._shape).T\n",
    "        D = (delta_at_nMin1 * self._identity).dot(D_at_n.T)\n",
    "        self._cov = self._cov * (self._count - 1) / self._count + D\n",
    "\n",
    "    def merge(self, other):\n",
    "        \"\"\"\n",
    "        Merges the current object and the given other object into a new OnlineCovariance object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        other: OnlineCovariance, The other OnlineCovariance to merge this object with.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        OnlineCovariance\n",
    "        \"\"\"\n",
    "        if other._order != self._order:\n",
    "            raise ValueError(\n",
    "                f\"\"\"\n",
    "                   Cannot merge two OnlineCovariances with different orders.\n",
    "                   ({self._order} != {other._order})\n",
    "                   \"\"\"\n",
    "            )\n",
    "\n",
    "        merged_cov = OnlineCovariance(self._order)\n",
    "        merged_cov._count = self.count + other.count\n",
    "        count_corr = (other.count * self.count) / merged_cov._count\n",
    "        merged_cov._mean = (\n",
    "            self.mean / other.count + other.mean / self.count\n",
    "        ) * count_corr\n",
    "        flat_mean_diff = self._mean - other._mean\n",
    "        shp = (self._order, self._order)\n",
    "        mean_diffs = np.broadcast_to(flat_mean_diff, self._shape).T\n",
    "        merged_cov._cov = (\n",
    "            self._cov * self.count\n",
    "            + other._cov * other._count\n",
    "            + mean_diffs * mean_diffs.T * count_corr\n",
    "        ) / merged_cov.count\n",
    "        return merged_cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb309ec",
   "metadata": {},
   "source": [
    "#### Save layer-wise covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3389d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from src.data.dataset_readers import DATASET_CLASSES\n",
    "from src.data.Batcher import Batcher\n",
    "from src.data.PytorchDataset import PytorchDataset\n",
    "\n",
    "# HPs\n",
    "DATASET_NAME = \"qasc\"\n",
    "MODEL_NAME = \"t5-base\"\n",
    "\n",
    "root_dir = osp.join(os.environ.get(\"SCRATCH\", \"\"), \"ties\", \"exp_out\", \"training\", MODEL_NAME)\n",
    "task_to_model_dict = {\n",
    "    'qasc': osp.join(root_dir, \"qasc\", \"best_model.pt\"),\n",
    "    'quartz': osp.join(root_dir, \"quartz\", \"best_model.pt\")\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "createPytorchDataset_fn = lambda dataset: PytorchDataset(dataset, tokenizer, device)\n",
    "\n",
    "dataset_kwargs = {\n",
    "    \"few_shot_random_seed\": None,\n",
    "    \"num_val_samples\": 32,\n",
    "    \"max_datapoints_per_dataset_without_templates\": None\n",
    "}\n",
    "\n",
    "dataset_reader = DATASET_CLASSES[DATASET_NAME](dataset_kwargs)\n",
    "batcher = Batcher(\n",
    "    dataset_reader,\n",
    "    createPytorchDataset_fn,\n",
    "    train_batchSize=32,\n",
    "    eval_batchSize=32,\n",
    "    world_size=1,\n",
    "    device=0,\n",
    ")\n",
    "train_iterator = batcher.get_trainBatches(\n",
    "    \"train\", 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fff9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 3/3 [01:06<00:00, 22.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.model.T5Wrapper import T5Wrapper\n",
    "\n",
    "# Init model\n",
    "transformer = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "model = T5Wrapper(transformer, tokenizer)\n",
    "\n",
    "# Optionally load state_dict\n",
    "# model.load_state_dict(torch.load(task_to_model_dict['qasc']))\n",
    "model.to(device)\n",
    "model.train()\n",
    "for _ in tqdm(range(3)):\n",
    "    out = next(train_iterator)\n",
    "    model(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d52c9729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for transformer.encoder.block.0.layer.0.SelfAttention.q\n",
      "Registering hook for transformer.encoder.block.0.layer.0.SelfAttention.k\n",
      "Registering hook for transformer.encoder.block.0.layer.0.SelfAttention.v\n",
      "Registering hook for transformer.encoder.block.0.layer.0.SelfAttention.o\n",
      "Registering hook for transformer.encoder.block.0.layer.1.DenseReluDense.wi\n",
      "Registering hook for transformer.encoder.block.0.layer.1.DenseReluDense.wo\n",
      "Registering hook for transformer.encoder.block.1.layer.0.SelfAttention.q\n",
      "Registering hook for transformer.encoder.block.1.layer.0.SelfAttention.k\n",
      "Registering hook for transformer.encoder.block.1.layer.0.SelfAttention.v\n",
      "Registering hook for transformer.encoder.block.1.layer.0.SelfAttention.o\n",
      "Registering hook for transformer.encoder.block.1.layer.1.DenseReluDense.wi\n",
      "Registering hook for transformer.encoder.block.1.layer.1.DenseReluDense.wo\n",
      "Registering hook for transformer.encoder.block.2.layer.0.SelfAttention.q\n",
      "Registering hook for transformer.encoder.block.2.layer.0.SelfAttention.k\n",
      "Registering hook for transformer.encoder.block.2.layer.0.SelfAttention.v\n",
      "Registering hook for transformer.encoder.block.2.layer.0.SelfAttention.o\n",
      "Registering hook for transformer.encoder.block.2.layer.1.DenseReluDense.wi\n",
      "Registering hook for transformer.encoder.block.2.layer.1.DenseReluDense.wo\n",
      "Registering hook for transformer.encoder.block.3.layer.0.SelfAttention.q\n",
      "Registering hook for transformer.encoder.block.3.layer.0.SelfAttention.k\n",
      "Registering hook for transformer.encoder.block.3.layer.0.SelfAttention.v\n",
      "Registering hook for transformer.encoder.block.3.layer.0.SelfAttention.o\n",
      "Registered 21 hooks\n",
      "Running forward passes\n",
      "Processing batch 0\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 3072])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 3072])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 3072])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "inp.shape torch.Size([32, 100, 768])\n",
      "Processing batch 1\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 3072])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 3072])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 3072])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "inp.shape torch.Size([32, 117, 768])\n",
      "Processing batch 2\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "Processing batch 3\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "Processing batch 4\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "Processing batch 5\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 3072])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "inp.shape torch.Size([32, 113, 768])\n",
      "Processing batch 6\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 3072])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "inp.shape torch.Size([32, 102, 768])\n",
      "Processing batch 7\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 3072])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 3072])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 3072])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "inp.shape torch.Size([32, 107, 768])\n",
      "Processing batch 8\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "Processing batch 9\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 3072])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 3072])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 3072])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "inp.shape torch.Size([32, 108, 768])\n",
      "Processing batch 10\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 3072])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 3072])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 3072])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "inp.shape torch.Size([32, 121, 768])\n",
      "Processing batch 11\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 3072])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 3072])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 3072])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "inp.shape torch.Size([32, 119, 768])\n",
      "Processing batch 12\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 3072])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 3072])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 3072])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "inp.shape torch.Size([32, 128, 768])\n",
      "Processing batch 13\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 3072])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "inp.shape torch.Size([32, 103, 768])\n",
      "Processing batch 14\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 3072])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 3072])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 3072])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "inp.shape torch.Size([32, 104, 768])\n",
      "Processing batch 15\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 3072])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 3072])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 3072])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "inp.shape torch.Size([32, 115, 768])\n",
      "Processing batch 16\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 3072])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "inp.shape torch.Size([32, 118, 768])\n",
      "Processing batch 17\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 3072])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 3072])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 3072])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "inp.shape torch.Size([32, 106, 768])\n",
      "Processing batch 18\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 3072])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 3072])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 3072])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "inp.shape torch.Size([32, 111, 768])\n",
      "Processing batch 19\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 3072])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 3072])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 3072])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "inp.shape torch.Size([32, 101, 768])\n",
      "Processing batch 20\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 3072])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 3072])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 3072])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "inp.shape torch.Size([32, 109, 768])\n",
      "Processing batch 21\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 3072])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 3072])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 3072])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n",
      "inp.shape torch.Size([32, 142, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "\n",
    "# Compute running covariance of activations\n",
    "stats = {}  # layer_name -> hook_result\n",
    "handles = []  # references to hooks\n",
    "MAX_HOOKS = 20\n",
    "MAX_BATCHES = 20\n",
    "\n",
    "# !! IMPORTANT !!::\n",
    "# Avoid running multiple times otherwise hooks will be registered multiple times\n",
    "\n",
    "# # Init model\n",
    "# transformer = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "# model = T5Wrapper(transformer, tokenizer)\n",
    "\n",
    "# # Optionally load state_dict\n",
    "# # model.load_state_dict(torch.load(task_to_model_dict['qasc']))\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "\n",
    "def hook(name):\n",
    "    # Hook gets (module, input, output)\n",
    "    def h(mod, _inp, out):\n",
    "        # print(\"out.shape\", out.shape)\n",
    "        inp = _inp[0]\n",
    "        if torch.is_tensor(inp):\n",
    "            print(\"inp.shape\", inp.shape)\n",
    "            B, T, D = inp.shape\n",
    "            if name not in stats:\n",
    "                ocov = OnlineCovariance(D)\n",
    "                stats[name] = ocov\n",
    "            ocov = stats[name]\n",
    "            for i in range(B):\n",
    "                j = torch.randint(0, T, (1,)).item()\n",
    "                v = inp[i, j].cpu().detach().numpy()\n",
    "                # normalize v\n",
    "                # v = v / np.linalg.norm(v)\n",
    "                ocov.add(v)\n",
    "            stats[name] = ocov\n",
    "    return h\n",
    "\n",
    "num_registered = 0\n",
    "for i, (module_name, m) in enumerate(model.named_modules()):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        print(\"Registering hook for\", module_name)\n",
    "        h = m.register_forward_hook(hook(module_name))\n",
    "        handles.append(h)\n",
    "        if num_registered > MAX_HOOKS:\n",
    "            break\n",
    "        num_registered += 1\n",
    "\n",
    "print(\"Registered\", num_registered, \"hooks\")\n",
    "\n",
    "# Run forward passes\n",
    "model.to(device)\n",
    "train_iterator = batcher.get_trainBatches(\n",
    "    \"train\", 0\n",
    ")\n",
    "with torch.no_grad():\n",
    "    print(\"Running forward passes\")\n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        print(\"Processing batch\", i)\n",
    "        model(batch)\n",
    "        if i > MAX_BATCHES:\n",
    "            break\n",
    "\n",
    "# Clear hooks\n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b2b6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.encoder.block.0.layer.0.SelfAttention.q (768, 768)\n",
      "transformer.encoder.block.0.layer.0.SelfAttention.k (768, 768)\n",
      "transformer.encoder.block.0.layer.0.SelfAttention.v (768, 768)\n",
      "transformer.encoder.block.0.layer.0.SelfAttention.o (768, 768)\n",
      "transformer.encoder.block.0.layer.1.DenseReluDense.wi (768, 768)\n",
      "transformer.encoder.block.0.layer.1.DenseReluDense.wo (3072, 3072)\n",
      "transformer.encoder.block.1.layer.0.SelfAttention.q (768, 768)\n",
      "transformer.encoder.block.1.layer.0.SelfAttention.k (768, 768)\n",
      "transformer.encoder.block.1.layer.0.SelfAttention.v (768, 768)\n",
      "transformer.encoder.block.1.layer.0.SelfAttention.o (768, 768)\n",
      "transformer.encoder.block.1.layer.1.DenseReluDense.wi (768, 768)\n",
      "transformer.encoder.block.1.layer.1.DenseReluDense.wo (3072, 3072)\n",
      "transformer.encoder.block.2.layer.0.SelfAttention.q (768, 768)\n",
      "transformer.encoder.block.2.layer.0.SelfAttention.k (768, 768)\n",
      "transformer.encoder.block.2.layer.0.SelfAttention.v (768, 768)\n",
      "transformer.encoder.block.2.layer.0.SelfAttention.o (768, 768)\n",
      "transformer.encoder.block.2.layer.1.DenseReluDense.wi (768, 768)\n",
      "transformer.encoder.block.2.layer.1.DenseReluDense.wo (3072, 3072)\n",
      "transformer.encoder.block.3.layer.0.SelfAttention.q (768, 768)\n",
      "transformer.encoder.block.3.layer.0.SelfAttention.k (768, 768)\n",
      "transformer.encoder.block.3.layer.0.SelfAttention.v (768, 768)\n",
      "transformer.encoder.block.3.layer.0.SelfAttention.o (768, 768)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "covs = {}\n",
    "means = {}\n",
    "for s in stats:\n",
    "    c = stats[s].cov\n",
    "    m = stats[s].mean\n",
    "    print(s, c.shape)\n",
    "    covs[s] = c\n",
    "    means[s] = m\n",
    "\n",
    "with open(os.path.join(results_dir, f\"covs_d{DATASET_NAME}_m{MODEL_NAME}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"covs\": covs,\n",
    "        \"means\": means,\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bf1bf",
   "metadata": {},
   "source": [
    "#### Analyze layer-wise covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c495444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.60.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.9/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9838ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load covs and means\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "RESULTS_DIR = \"results\"\n",
    "DATASET_NAME = \"qasc\"\n",
    "MODEL_NAME = \"t5-base\"\n",
    "\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, f\"covs_d{DATASET_NAME}_m{MODEL_NAME}.pkl\"), \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "covs = data[\"covs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0776737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pdf\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "start_idx = 0\n",
    "stop_idx = 500 + start_idx\n",
    "\n",
    "with PdfPages(f\"covs_heatmaps_start{start_idx}_stop{stop_idx}.pdf\") as pdf:\n",
    "    for i, (c_mat_name, c_mat) in enumerate(covs.items()):\n",
    "        plt.figure(figsize=(16, 16))\n",
    "        ax = sns.heatmap(\n",
    "            np.abs(c_mat[start_idx:stop_idx, start_idx:stop_idx]),\n",
    "            cmap=\"rocket\",\n",
    "            annot=False,\n",
    "            linewidths=0,    # <-- no grid lines\n",
    "        )\n",
    "        ax.set_xticks([])  # <-- no ticks\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        plt.title(c_mat_name.split(\".\")[-2:] + [f\" Start {start_idx} Stop {stop_idx}\"])\n",
    "        pdf.savefig()\n",
    "        plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
